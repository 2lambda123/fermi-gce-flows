{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file is part of sbi, a toolkit for simulation-based inference. sbi is licensed\n",
    "# under the Affero General Public License v3, see <https://www.gnu.org/licenses/>.\n",
    "\n",
    "# This provides a test for gpu performance. A simulator of images is defined so that\n",
    "# preprocessing with an embedding net becomes necessary. The test shows that only when\n",
    "# using a CNN embedding net a substantial speed up of training can be achieved by using\n",
    "# the GPU. For comparison a tall linear network is used as embedding net - without\n",
    "# speed up.\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import pytest\n",
    "from torch import zeros\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from sbi import utils as utils\n",
    "from sbi.inference import SNPE, SNLE, SNRE, prepare_for_sbi\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sbi.simulators import simulate_in_batches\n",
    "from sbi.utils.torchutils import process_device\n",
    "\n",
    "\n",
    "# Simulator of 32x32 images.\n",
    "def simulator_model(params, return_points=False):\n",
    "    \"\"\" Simulator model with two-dimensional input parameter and 1024-dimensional output\n",
    "    This simulator serves as a basic example for using a neural net for learning\n",
    "    summary features.\n",
    "    It has only two input parameters but generates high-dimensional output vectors.\n",
    "    The data is generated as follows:\n",
    "        (-) Input:  parameter = [r, theta]\n",
    "        (1) Generate 100 two-dimensional points centered around (r cos(theta),r sin\n",
    "            (theta)) and perturb by a Gaussian noise with variance 0.01\n",
    "        (2) Create a grayscale image of the scattered points with dimensions 32 by 32\n",
    "        (3) Perturb the image with an uniform noise with values betweeen 0 and 0.2\n",
    "    Parameters\n",
    "    ----------\n",
    "    parameter : array-like, shape (2)\n",
    "        The two input parameters of the model, ordered as [r, theta]\n",
    "    return_points : bool (default: False)\n",
    "        Whether the simulator should return the coordinates of the simulated data\n",
    "        points as well\n",
    "    Returns\n",
    "    -------\n",
    "    image: torch tensor, shape (1, 1024)\n",
    "        Output flattened image\n",
    "    (optional) points: array-like, shape (100, 2)\n",
    "        Coordinates of the 2D simulated data points\n",
    "    \"\"\"\n",
    "    r, theta = params\n",
    "\n",
    "    sigma_points = 0.10\n",
    "    npoints = 100\n",
    "    nx = 32\n",
    "    ny = 32\n",
    "    sigma_image = 0.20\n",
    "\n",
    "    points = []\n",
    "\n",
    "    # Generate points according to params and add noise.\n",
    "    points = torch.tensor(\n",
    "        [[r * torch.cos(theta), r * torch.sin(theta)]]\n",
    "    ) + sigma_points * torch.randn(npoints, 2)\n",
    "\n",
    "    # Find indices of points within unit circle in image.\n",
    "    image = zeros((nx, ny))\n",
    "    for point in points:\n",
    "        pi = int((point[0] - (-1)) / ((+1) - (-1)) * nx)\n",
    "        pj = int((point[1] - (-1)) / ((+1) - (-1)) * ny)\n",
    "        if (pi < nx) and (pj < ny):\n",
    "            image[pi, pj] = 1\n",
    "    # Add uniform noise.\n",
    "    image += sigma_image * torch.rand(nx, ny)\n",
    "    image = image.T\n",
    "    image = image.reshape(1, -1)\n",
    "\n",
    "    if return_points:\n",
    "        return image, points\n",
    "    else:\n",
    "        return image\n",
    "\n",
    "\n",
    "class CNNEmbedding(nn.Module):\n",
    "    \"\"\"Big CNN embedding net to levarage GPU computation.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 2D convolutional layer\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=6, kernel_size=5, padding=2)\n",
    "        # Maxpool layer that reduces 32x32 image to 4x4\n",
    "        self.pool = nn.MaxPool2d(kernel_size=8, stride=8)\n",
    "        # Fully connected layer taking as input the 6 flattened output arrays from the\n",
    "        # maxpooling layer\n",
    "        self.fc = nn.Linear(in_features=6 * 4 * 4, out_features=8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, 32, 32)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 6 * 4 * 4)\n",
    "        x = F.relu(self.fc(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "@pytest.mark.slow\n",
    "@pytest.mark.requires_cuda\n",
    "@pytest.mark.parametrize(\n",
    "    \"method, model\",\n",
    "    [(SNPE, \"mdn\"), (SNPE, \"maf\"), (SNLE, \"nsf\"), (SNRE, \"mlp\"), (SNRE, \"resnet\")],\n",
    ")\n",
    "def test_gpu_training(method, model):\n",
    "\n",
    "    num_dim = 2\n",
    "    num_samples = 10\n",
    "    num_simulations = 500\n",
    "    num_workers = 10\n",
    "    max_num_epochs = 5\n",
    "\n",
    "    prior = utils.BoxUniform(zeros(num_dim), torch.tensor([1.0, 2.0 * np.pi]))\n",
    "\n",
    "    simulator, prior = prepare_for_sbi(simulator_model, prior)\n",
    "\n",
    "    theta_o = torch.tensor([[0.7, np.pi / 4.0]])\n",
    "    x_o = simulator(theta_o)\n",
    "\n",
    "    # Pre simulate to have same training data for cpu and gpu.\n",
    "    thetas = prior.sample((num_simulations,))\n",
    "    xos = simulate_in_batches(\n",
    "        simulator, thetas, num_workers=num_workers, show_progress_bars=False\n",
    "    )\n",
    "    \n",
    "    if method == SNPE:\n",
    "        kwargs = dict(\n",
    "            density_estimator=utils.posterior_nn(\n",
    "                model=model,\n",
    "                # Needed to avoid doubles for some testing scenarios.\n",
    "                embedding_net=CNNEmbedding(),\n",
    "                hidden_features=40,\n",
    "                num_transforms=2,\n",
    "            ),\n",
    "            sample_with_mcmc=True,\n",
    "            mcmc_method=\"slice_np\",\n",
    "        )\n",
    "    elif method == SNLE:\n",
    "        kwargs = dict(\n",
    "            density_estimator=utils.likelihood_nn(\n",
    "                model=model,\n",
    "                # Needed to avoid doubles for some testing scenarios.\n",
    "                hidden_features=40,\n",
    "                num_transforms=2,\n",
    "            ),\n",
    "            mcmc_method=\"slice\",\n",
    "        )\n",
    "    elif method == SNRE:\n",
    "        kwargs = dict(\n",
    "            classifier=utils.classifier_nn(\n",
    "                model=model,\n",
    "                # Needed to avoid doubles for some testing scenarios.\n",
    "                embedding_net_x=CNNEmbedding(),\n",
    "                hidden_features=40,\n",
    "            ),\n",
    "            mcmc_method=\"slice\",\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError()\n",
    "\n",
    "    # Record cpu and gpu runtime during training\n",
    "    training_times = []\n",
    "    for device in [\"cpu\", \"cuda:0\"]:\n",
    "        infer = method(\n",
    "            simulator, prior, show_progress_bars=False, device=device, **kwargs,\n",
    "        )\n",
    "        \n",
    "        infer.provide_presimulated(thetas, xos)\n",
    "\n",
    "        tic = time.time()\n",
    "        posterior = infer(\n",
    "            num_simulations=0, training_batch_size=100, max_num_epochs=max_num_epochs\n",
    "        ).set_default_x(x_o)\n",
    "        toc = time.time() - tic\n",
    "        print(f\"{device} training time: {toc:.2f}\")\n",
    "        training_times.append(toc)\n",
    "\n",
    "        tic = time.time()\n",
    "        samples = posterior.sample((num_samples,), show_progress_bars=False)\n",
    "        print(f\"{device} sampling time: {time.time() - tic:.2f}\")\n",
    "\n",
    "    assert (\n",
    "        training_times[0] > training_times[1]\n",
    "    ), \"For CNN embedding GPU must be faster than CPU.\"\n",
    "\n",
    "\n",
    "def test_process_device(device: str):\n",
    "    process_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_process_device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tuning bracket width...:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu training time: 2.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tuning bracket width...: 100%|██████████| 50/50 [00:02<00:00, 17.04it/s]\n",
      "Generating samples: 100%|██████████| 20/20 [00:05<00:00,  3.78it/s]\n",
      "Generating samples: 100%|██████████| 10/10 [00:02<00:00,  3.56it/s]\n",
      "/home/sm8383/anaconda3/lib/python3.8/site-packages/sbi-0.13.2-py3.8.egg/sbi/utils/torchutils.py:26: UserWarning: GPU was selected as a device for training the neural network. Note\n",
      "                   that we expect **no** significant speed ups in training for the\n",
      "                   default architectures we provide. Using the GPU will be effective\n",
      "                   only for large neural networks with operations that are fast on the\n",
      "                   GPU, e.g., for a CNN or RNN `embedding_net`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu sampling time: 11.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tuning bracket width...:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 training time: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tuning bracket width...: 100%|██████████| 50/50 [00:04<00:00, 11.32it/s]\n",
      "Generating samples: 100%|██████████| 20/20 [00:08<00:00,  2.47it/s]\n",
      "Generating samples: 100%|██████████| 10/10 [00:04<00:00,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 sampling time: 16.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_gpu_training(SNPE, \"maf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
